# NOTE: Not
# SOURCE: https://grafana.com/docs/loki/latest/clients/promtail/configuration/
# SOURCE: https://github.com/coopsymbiotic/coopsymbiotic-ansible/blob/07a07c52c8cbe1fa918bc24c6725d5f7b03a7d29/roles/promtail/templates/etc/promtail.yaml
server:
    http_listen_port: 9080
    grpc_listen_port: 0
    log_level: "info"

    # THIS IS WHY WE ARE NOT GETTING LOKI LOGS CURRENTLY
    #FIXME: https://github.com/grafana/loki/issues/3335
    #FIXME: https://github.com/grafana/loki/issues/3335
    #FIXME: https://github.com/grafana/loki/issues/3335
    #FIXME: https://github.com/grafana/loki/issues/3335
    #FIXME: https://github.com/grafana/loki/issues/3335
    #FIXME: https://github.com/grafana/loki/issues/3335
    #FIXME: https://github.com/grafana/loki/issues/3335
    #FIXME: https://github.com/grafana/loki/issues/3335
    #FIXME: https://github.com/grafana/loki/issues/3335
    #FIXME: https://github.com/grafana/loki/issues/3335
    #FIXME: https://github.com/grafana/loki/issues/3335

    # # Disable the HTTP and GRPC server.
    # [disable: <boolean> | default = false]

    # # HTTP server listen host
    # [http_listen_address: <string>]

    # # HTTP server listen port (0 means random port)
    # [http_listen_port: <int> | default = 80]

    # # gRPC server listen host
    # [grpc_listen_address: <string>]

    # # gRPC server listen port (0 means random port)
    # [grpc_listen_port: <int> | default = 9095]

    # # Register instrumentation handlers (/metrics, etc.)
    # [register_instrumentation: <boolean> | default = true]

    # # Timeout for graceful shutdowns
    # [graceful_shutdown_timeout: <duration> | default = 30s]

    # # Read timeout for HTTP server
    # [http_server_read_timeout: <duration> | default = 30s]

    # # Write timeout for HTTP server
    # [http_server_write_timeout: <duration> | default = 30s]

    # # Idle timeout for HTTP server
    # [http_server_idle_timeout: <duration> | default = 120s]

    # # Max gRPC message size that can be received
    # [grpc_server_max_recv_msg_size: <int> | default = 4194304]

    # # Max gRPC message size that can be sent
    # [grpc_server_max_send_msg_size: <int> | default = 4194304]

    # # Limit on the number of concurrent streams for gRPC calls (0 = unlimited)
    # [grpc_server_max_concurrent_streams: <int> | default = 100]

    # # Log only messages with the given severity or above. Supported values [debug,
    # # info, warn, error]
    # [log_level: <string> | default = "info"]

    # # Base path to server all API routes from (e.g., /v1/).
    # [http_path_prefix: <string>]

    # # Target managers check flag for Promtail readiness, if set to false the check is ignored
    # [health_check_target: <bool> | default = true]

positions:
    filename: /tmp/positions.yaml

    # # Location of positions file
    # [filename: <string> | default = "/var/log/positions.yaml"]

    # # How often to update the positions file
    # [sync_period: <duration> | default = 10s]

    # # Whether to ignore & later overwrite positions files that are corrupted
    # [ignore_invalid_yaml: <boolean> | default = false]


clients:
    - url: http://192.168.1.98:3100/loki/api/v1/push
      # # The URL where Loki is listening, denoted in Loki as http_listen_address and
      # # http_listen_port. If Loki is running in microservices mode, this is the HTTP
      # # URL for the Distributor. Path to the push API needs to be included.
      # # Example: http://example.com:3100/loki/api/v1/push
      # url: <string>

      # # The tenant ID used by default to push logs to Loki. If omitted or empty
      # # it assumes Loki is running in single-tenant mode and no X-Scope-OrgID header
      # # is sent.
      # [tenant_id: <string>]

      # # Maximum amount of time to wait before sending a batch, even if that
      # # batch isn't full.
      # [batchwait: <duration> | default = 1s]

      # # Maximum batch size (in bytes) of logs to accumulate before sending
      # # the batch to Loki.
      # [batchsize: <int> | default = 1048576]

      # # If using basic auth, configures the username and password
      # # sent.
      # basic_auth:
      #   # The username to use for basic auth
      #   [username: <string>]

      #   # The password to use for basic auth
      #   [password: <string>]

      #   # The file containing the password for basic auth
      #   [password_file: <filename>]

      # # Optional OAuth 2.0 configuration
      # # Cannot be used at the same time as basic_auth or authorization
      # oauth2:
      #   # Client id and secret for oauth2
      #   [client_id: <string>]
      #   [client_secret: <secret>]

      #   # Read the client secret from a file
      #   # It is mutually exclusive with `client_secret`
      #   [client_secret_file: <filename>]

      #   # Optional scopes for the token request
      #   scopes:
      #     [ - <string> ... ]

      #   # The URL to fetch the token from
      #   token_url: <string>

      #   # Optional parameters to append to the token URL
      #   endpoint_params:
      #     [ <string>: <string> ... ]

      # # Bearer token to send to the server.
      # [bearer_token: <secret>]

      # # File containing bearer token to send to the server.
      # [bearer_token_file: <filename>]

      # # HTTP proxy server to use to connect to the server.
      # [proxy_url: <string>]

      # # If connecting to a TLS server, configures how the TLS
      # # authentication handshake will operate.
      # tls_config:
      #   # The CA file to use to verify the server
      #   [ca_file: <string>]

      #   # The cert file to send to the server for client auth
      #   [cert_file: <filename>]

      #   # The key file to send to the server for client auth
      #   [key_file: <filename>]

      #   # Validates that the server name in the server's certificate
      #   # is this value.
      #   [server_name: <string>]

      #   # If true, ignores the server certificate being signed by an
      #   # unknown CA.
      #   [insecure_skip_verify: <boolean> | default = false]

      # # Configures how to retry requests to Loki when a request
      # # fails.
      # # Default backoff schedule:
      # # 0.5s, 1s, 2s, 4s, 8s, 16s, 32s, 64s, 128s, 256s(4.267m)
      # # For a total time of 511.5s(8.5m) before logs are lost
      # backoff_config:
      #   # Initial backoff time between retries
      #   [min_period: <duration> | default = 500ms]

      #   # Maximum backoff time between retries
      #   [max_period: <duration> | default = 5m]

      #   # Maximum number of retries to do
      #   [max_retries: <int> | default = 10]

      # # Static labels to add to all logs being sent to Loki.
      # # Use map like {"foo": "bar"} to add a label foo with
      # # value bar.
      # # These can also be specified from command line:
      # # -client.external-labels=k1=v1,k2=v2
      # # (or --client.external-labels depending on your OS)
      # # labels supplied by the command line are applied
      # # to all clients configured in the `clients` section.
      # # NOTE: values defined in the config file will replace values
      # # defined on the command line for a given client if the
      # # label keys are the same.
      # external_labels:
      #   [ <labelname>: <labelvalue> ... ]

      # # Maximum time to wait for a server to respond to a request
      # [timeout: <duration> | default = 10s]

      # # A comma-separated list of labels to include in the stream lag metric `promtail_stream_lag_seconds`.
      # # The default value is "filename". A "host" label is always included.
      # # The stream lag metric indicates which streams are falling behind on writes to Loki;
      # # be mindful about using too many labels, as it can increase cardinality.
      # [stream_lag_labels: <string> | default = "filename"]



scrape_configs:
  # - job_name: system
  #   static_configs:
  #   - targets:
  #       - localhost
  #     labels:
  #       miner: boss-monitor
  #       job: varlogs
  #       __path__: /var/log/*log

  # - job_name: rsyslogng
  #   static_configs:
  #   - targets:
  #       - localhost
  #     labels:
  #       miner: boss-monitor
  #       job: rsyslogng
  #       __path__: /log/client_logs/*/*log


  - job_name: rsyslogng
    static_configs:
    - targets:
        - localhost
      labels:
        miner: boss-monitor
        job: rsyslogng
        __path__: /log/client_logs/*/messages.log
    pipeline_stages:
    - match:
        selector: '{job="rsyslogng"} |~ ".*sshd.*Received disconnect from .* Bye Bye .preauth.*"'
        action: drop
        drop_counter_reason: promtail_noisy_error
    - match:
        selector: '{job="rsyslogng"} |~ ".*sshd.*Disconnected from .*preauth.*"'
        action: drop
        drop_counter_reason: promtail_noisy_error
    - match:
        selector: '{job="rsyslogng"} |~ ".* promtail\\[.*"'
        action: drop
        drop_counter_reason: promtail_noisy_error

    # # EXAMPLE: Apr 18 20:24:04 UniFiSecurityGateway3P kernel: [LAN_LOCAL-default-A]IN=eth1 OUT= MAC=80:2a:a8:00:11:33:00:11:22:33:44:66:08:00 SRC=192.168.1.8 DST=192.168.1.1 LEN=52 TOS=0x00 PREC=0x00 TTL=64 ID=61516 DF PROTO=TCP SPT=8080 DPT=45096 WINDOW=246 RES=0x00 ACK URGP=0
    # # EXAMPLE: Apr 18 20:54:31 UniFiSecurityGateway3P kernel: [WAN_LOCAL-4000-D]IN=eth0 OUT= MAC=80:2a:a8:00:11:33:00:11:22:33:44:66:08:00 SRC=172.217.10.138 DST=192.168.0.3 LEN=115 TOS=0x00 PREC=0x00 TTL=122 ID=53703 PROTO=TCP SPT=443 DPT=52170 WINDOW=294 RES=0x00 ACK PSH URGP=0
    # # EXAMPLE: Apr 18 20:54:32 UniFiSecurityGateway3P kernel: [LAN_LOCAL-default-A]IN=eth1 OUT= MAC=80:2a:a8:00:11:33:00:11:22:33:44:66:08:00 SRC=192.168.1.212 DST=192.168.1.1 LEN=102 TOS=0x00 PREC=0x00 TTL=64 ID=2810 PROTO=UDP SPT=61080 DPT=53 LEN=82
    # # SOURCE: https://grokconstructor.appspot.com/do/constructionstep
    # - match:
    #     # selector: '{job="rsyslogng"} |~ ".*kernel.*"'
    #     selector: '{container_name="bossjones/fluentd-elasticsearch:v4.0.0"}'
    #     stages:
    #     - regex:
    #         # Example: "Apr  7 18:56:11 ubnt kernel: "
    #         expression: '(?P<time>^((\d\d){1,2})-((?:0?[1-9]|1[0-2]))-((?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])) (([^0-9]?)((?:2[0123]|[01]?[0-9])):((?:[0-5][0-9]))(?::((?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)))([^0-9]?)) ((?:Z|[+-]((?:2[0123]|[01]?[0-9]))(?::?((?:[0-5][0-9])))))) (?P<fluentd_label>.*?): (?P<fluentd_message>.*)'
    #     - labels:
    #         time:
    #         fluentd_message:

    #     - json:
    #         expressions:
    #           output: fluentd_message
    #           hostname: hostname
    #           timestamp: time
    #           message: message
    #           process_name: process_name
    #           firewall_interface: firewall_interface
    #           firewall_rule_index: firewall_rule_index
    #           firewall_rule_action: firewall_rule_action
    #           iptables_output_device: iptables_output_device
    #           mac: mac
    #           destination_mac: destination_mac
    #           source_mac: source_mac
    #           iptables_ether_type: iptables_ether_type
    #           firewall_destination_ip: firewall_destination_ip
    #           firewall_packet_length: firewall_packet_length
    #           firewall_tos: firewall_tos
    #           firewall_precidence_field: firewall_precidence_field
    #           firewall_ttl: firewall_ttl
    #           firewall_id: firewall_id
    #           firewall_dont_fragment: firewall_dont_fragment
    #           firewall_nf_protocol: firewall_nf_protocol
    #           firewall_spt: firewall_spt
    #           firewall_dtp: firewall_dtp
    #           firewall_tcp_opts: firewall_tcp_opts
    #           remote_ip: remote_ip
    #           extra:
    #     - json:
    #         expressions:
    #           geoip:
    #         source: extra

    #     - timestamp:
    #         source: time
    #         format: "2022-04-08 22:40:46.000000000 +0000"

    #     - output:
    #         # # Name from extracted data to use for the log entry.
    #         source: message

    #     # - regex:
    #     #     # Example: [LAN_LOCAL-default-A]
    #     #     expression: '(?:(\[(?P<firewall_interface>\b\w+\b)-(?P<firewall_rule_index>\b\w+\b)-(?P<firewall_rule_action>\b\w+\b)\]))'
    #     # - labels:
    #     #     firewall_interface:
    #     #     firewall_rule_index:
    #     #     firewall_rule_action:

    #     # - regex:
    #     #     # Example: [LAN_LOCAL-default-A]
    #     #     expression: '(?:(\[(?P<firewall_interface>\b\w+\b)-(?P<firewall_rule_index>\b\w+\b)-(?P<firewall_rule_action>\b\w+\b)\]))?'
    #     # - labels:
    #     #     firewall_interface:
    #     #     firewall_rule_index:
    #     #     firewall_rule_action:


  - job_name: remotebootlog
    static_configs:
    - targets:
        - localhost
      labels:
        miner: boss-monitor
        job: remotebootlog
        __path__: /log/client_logs/*/boot.log

  # - job_name: remotemessages
  #   static_configs:
  #   - targets:
  #       - localhost
  #     labels:
  #       miner: boss-monitor
  #       job: remotemessages
  #       __path__: /log/client_logs/*/messages.log

  - job_name: remotecron
    static_configs:
    - targets:
        - localhost
      labels:
        miner: boss-monitor
        job: remotecron
        __path__: /log/client_logs/*/cron.log

  - job_name: remotesecure
    static_configs:
    - targets:
        - localhost
      labels:
        miner: boss-monitor
        job: remotesecure
        __path__: /log/client_logs/*/secure.log

  - job_name: remoteuncategorized
    static_configs:
    - targets:
        - localhost
      labels:
        miner: boss-monitor
        job: remoteuncategorized
        __path__: /log/client_logs/*/uncategorized.log


  - job_name: journal
    journal:
      json: true
      max_age: 12h
      path: /var/log/journal
      labels:
        job: systemd-journal
    relabel_configs:
      - source_labels: ['__journal__systemd_unit']
        target_label: 'unit'
      - source_labels: ['__journal_container_name']
        target_label: 'container'
      # - source_labels: ['__journal_syslog_identifier']
      #   target_label: 'syslog_identifier'
      # - source_labels: ['__journal__hostname']
      #   target_label: 'hostname'
      - source_labels: ['__journal__comm']
        target_label: 'comm'
      - source_labels: ['__journal__uid']
        target_label: 'uid'

      # SOURCE: https://github.com/open-io/ansible-role-openio-promtail/blob/b0d4ee9d50a41f03395db4dfead60d26fad62f0c/templates/config.yml.j2
      # Extract hostname
      - action: replace
        source_labels: ['__journal__hostname']
        target_label: 'host'

      # extract and convert priority to log_leve
      - action: replace
        source_labels: ['__journal_priority']
        target_label: 'level'
        regex: '^0$'
        replacement: 'EMERG'

      - action: replace
        source_labels: ['__journal_priority']
        target_label: 'level'
        regex: '^1$'
        replacement: 'ALERT'

      - action: replace
        source_labels: ['__journal_priority']
        target_label: 'level'
        regex: '^2$'
        replacement: 'CRIT'

      - action: replace
        source_labels: ['__journal_priority']
        target_label: 'level'
        regex: '^3$'
        replacement: 'ERROR'

      - action: replace
        source_labels: ['__journal_priority']
        target_label: 'level'
        regex: '^4$'
        replacement: 'WARNING'

      - action: replace
        source_labels: ['__journal_priority']
        target_label: 'level'
        regex: '^5$'
        replacement: 'NOTICE'

      - action: replace
        source_labels: ['__journal_priority']
        target_label: 'level'
        regex: '^6$'
        replacement: 'INFO'

      - action: replace
        source_labels: ['__journal_priority']
        target_label: 'level'
        regex: '^7$'
        replacement: 'DEBUG'

      # extract and convert syslog_facility
      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^0$'
        replacement: 'KERN'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^1$'
        replacement: 'USER'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^2$'
        replacement: 'MAIL'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^3$'
        replacement: 'DAEMON'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^4$'
        replacement: 'AUTH'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^5$'
        replacement: 'SYSLOG'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^6$'
        replacement: LPR''

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^7$'
        replacement: 'NEWS'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^8$'
        replacement: 'UUCP'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^9$'
        replacement: 'CRON'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^10$'
        replacement: 'AUTHPRIV'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^11$'
        replacement: 'FTP'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^16$'
        replacement: 'LOCAL0'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^17$'
        replacement: 'LOCAL1'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^18$'
        replacement: 'LOCAL2'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^19$'
        replacement: 'LOCAL3'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^20$'
        replacement: 'LOCAL4'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^21$'
        replacement: 'LOCAL5'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^22$'
        replacement: 'LOCAL6'

      - action: replace
        source_labels: ['__journal_syslog_facility']
        target_label: 'facility'
        regex: '^23$'
        replacement: 'LOCAL7'

      # only keep lines with specific OIO syslog identifier
      - action: keep
        regex: 'OIO,\w+,\w+,\d+'
        source_labels: ['__journal_syslog_identifier']

      # extract namespace from syslog identifier
      - action: replace
        source_labels: ['__journal_syslog_identifier']
        target_label: namespace
        regex: 'OIO,(\w+),\w+,\d+'
        replacement: '${1}'

      # extract service_type from syslog identifier
      - action: replace
        source_labels: ['__journal_syslog_identifier']
        target_label: service_type
        regex: 'OIO,\w+,(\w+),\d+'
        replacement: '${1}'

      # extract service from syslog identifier
      - action: replace
        source_labels: ['__journal_syslog_identifier']
        target_label: service
        regex: 'OIO,\w+,(\w+),(\d+)'
        replacement: '${1}-${2}'

      # drop line related to log services
      - action: drop
        regex: '^(loki|promtail|elasticsearch|kibana|filebeat)$'
        source_labels: ['service_type']


  - job_name: syslog
    syslog:
      listen_address: 0.0.0.0:9514
      idle_timeout: 60s
      label_structured_data: yes
      labels:
        job: "syslog"
    relabel_configs:
      # - source_labels: ['__syslog_message_hostname']
      #   target_label: 'hostname'
      - source_labels: ['__syslog_connection_ip_address']
        target_label: 'ip_address'
      - source_labels: ['__syslog_message_severity']
        target_label: 'severity'
      - source_labels: ['__syslog_message_facility']
        target_label: 'facility'
      - source_labels: ['__syslog_message_app_name']
        target_label: 'app'
      - source_labels: ['__syslog_message_hostname']
        target_label: 'host'
      - action: labelmap
        regex: __syslog_message_(.+)


  # # SOURCE: https://github.com/rafaribe/home-ops/blob/d9e283fd3ddc42a9891c8a12fe82fa128657798a/provision/ansible/backup-server/roles/syncthing/templates/agent.yml
  # - job_name: system
  #   static_configs:
  #   - targets:
  #       - localhost
  #     labels:
  #       miner: boss-monitor
  #       job: varlogs
  #       __path__: //var/log/*log

  - job_name: containers
    static_configs:
    - targets:
        - localhost
      labels:
        server: boss-monitor
        job: containerlogs
        __path__: /var/lib/docker/containers/*/*log
    pipeline_stages:
    ################################################################################
    # remove all noise
    ################################################################################
    # - match:
    #     selector: '{job="containerlogs"} |~ ".*firewall_source_ip is empty string.*"'
    #     action: drop
    #     drop_counter_reason: promtail_noisy_error
    # - match:
    #     selector: '{job="containerlogs"} |~ ".* ath0: track: .*"'
    #     action: drop
    #     drop_counter_reason: promtail_noisy_error
    # - match:
    #     selector: '{job="containerlogs"} |~ ".* ubnt_protocol.ubnt_protocol_recv(): failed to decrypt the message.*"'
    #     action: drop
    #     drop_counter_reason: promtail_noisy_error

    ################################################################################
    # generic catch all for all docker containers
    ################################################################################
    - json:
        expressions:
          output: log
          stream: stream
          attrs:
          time:
    - json:
        expressions:
          tag:
        source: attrs
    - regex:
        expression: (?P<container_name>(?:[^|]*[^|]))
        source: tag
    - timestamp:
        format: RFC3339Nano
        source: time
    - labels:
        stream:
        container_name:
    - drop:
        expression: ".*firewall_source_ip is empty string.*"
        # source: fluentd_message
    - drop:
        expression: ".* ath0: track: .*"
        # source: fluentd_message
    - drop:
        expression: ".* failed to decrypt the message.*"
        # source: fluentd_message
    # - match:
    #     # drop all logs for all containers that don't have --log-opt: tag: "{{:ImageName}}|{{:Name}}"
    #     selector: '{job="containerlogs",container_name=""}'
    #     action: drop
    - output:
        source: output

# FIXME: NEED TO COMMENT THIS OUT CAUSE IT IS BREAKING LOKI SEE ERROR BELOW:
# loki             | level=warn ts=2022-06-12T22:43:11.101245953Z caller=grpc_logging.go:38 method=/logproto.Pusher/Push duration=118.097312ms err="rpc error: code = Code(429) desc = Maximum active stream limit exceeded, reduce the number of active streams (reduce labels or reduce label values), or contact your Loki administrator to see if the limit can be increased" msg="gRPC\n"
# ERROR: https://github.com/grafana/loki/issues/3335

# # EXAMPLE: https://github.com/nautible/nautible-infra/blob/34914fb370aacbdd46150cea7ed72c677ca60044/ArgoCD/ecosystems/base/observation/promtail/application.yaml
# - match: # unifi logs
#     # unifi iptable logs
#     # selector: '{container_name="bossjones/fluentd-elasticsearch:v4.0.0"} |~ ".*unifi.syslog.*"'
#     selector: '{container_name="bossjones/fluentd-elasticsearch:v4.0.0"} |~ ".*unifi.syslog.*"'
#     stages:
#     - regex:
#         expression: '(?P<fluentd_time>^((\d\d){1,2})-((?:0?[1-9]|1[0-2]))-((?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])) (([^0-9]?)((?:2[0123]|[01]?[0-9])):((?:[0-5][0-9]))(?::((?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)))([^0-9]?)) ((?:Z|[+-]((?:2[0123]|[01]?[0-9]))(?::?((?:[0-5][0-9])))))) (?P<fluentd_label>.*?): (?P<fluentd_message>.*)'
#         source: output
#     ################################################################################
#     # remove all noise
#     ################################################################################
#     - labels:
#         stream:
#         container_name:
#         fluentd_time:
#         fluentd_label:
#         fluentd_message:
#     - replace:
#         expression: "(.+)"
#         replace: "{{fromJson .Value}}"
#         source: fluentd_message
#     - output:
#         source: fluentd_message
# FIXME: NEED TO COMMENT THIS OUT CAUSE IT IS BREAKING LOKI SEE ERROR BELOW:
# loki             | level=warn ts=2022-06-12T22:43:11.101245953Z caller=grpc_logging.go:38 method=/logproto.Pusher/Push duration=118.097312ms err="rpc error: code = Code(429) desc = Maximum active stream limit exceeded, reduce the number of active streams (reduce labels or reduce label values), or contact your Loki administrator to see if the limit can be increased" msg="gRPC\n"
# ERROR: https://github.com/grafana/loki/issues/3335


    # #################################################
    # # non unifi logs
    # #################################################
    # - match:
    #     # selector: '{job="containerlogs"} !~ ".*unifi.syslog.*"'
    #     selector: '{job="containerlogs"}'
    #     stages:
    #     - json:
    #         expressions:
    #           output: log
    #           stream: stream
    #           attrs:
    #           time:
    #     - json:
    #         expressions:
    #           tag:
    #         source: attrs
    #     - regex:
    #         expression: (?P<container_name>(?:[^|]*[^|]))
    #         source: tag
    #     - timestamp:
    #         format: RFC3339Nano
    #         source: time
    #     - regex:
    #         expression: '(?P<fluentd_time>^((\d\d){1,2})-((?:0?[1-9]|1[0-2]))-((?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])) (([^0-9]?)((?:2[0123]|[01]?[0-9])):((?:[0-5][0-9]))(?::((?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)))([^0-9]?)) ((?:Z|[+-]((?:2[0123]|[01]?[0-9]))(?::?((?:[0-5][0-9])))))) (?P<fluentd_label>.*?): (?P<fluentd_message>\{.*\})'
    #         source: output
    #     - labels:
    #         stream:
    #         container_name:
    #         fluentd_time:
    #         fluentd_label:
    #         fluentd_message:
    #     # - json:
    #     #     expressions:
    #     #       log_line: fluentd_message
    #     #     source: fluentd_message
    #     # - replace:
    #     #     expression: ".*\\r.*"
    #     #     replace: ""
    #     # take string encoded part, and turn it into json
    #     # - replace:
    #     #     expression: ".*null.*"
    #     #     replace: ""
    #     - replace:
    #         expression: "(.+)"
    #         replace: "{{fromJson .Value}}"
    #         source: fluentd_message
    #     - output:
    #         source: output

    # #################################################
    # # unifi logs
    # #################################################
    # - match:
    #     selector: '{job="containerlogs"} |~ ".*unifi.syslog.*"'
    #     stages:
    #       - json:
    #           expressions:
    #             output: log
    #             stream: stream
    #             attrs:
    #             time:
    #       - json:
    #           expressions:
    #             tag:
    #           source: attrs
    #       - regex:
    #           expression: (?P<container_name>(?:[^|]*[^|]))
    #           source: tag
    #       - timestamp:
    #           format: RFC3339Nano
    #           source: time
    #       - regex:
    #           expression: '(?P<fluentd_time>^((\d\d){1,2})-((?:0?[1-9]|1[0-2]))-((?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])) (([^0-9]?)((?:2[0123]|[01]?[0-9])):((?:[0-5][0-9]))(?::((?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)))([^0-9]?)) ((?:Z|[+-]((?:2[0123]|[01]?[0-9]))(?::?((?:[0-5][0-9])))))) (?P<fluentd_label>.*?): (?P<fluentd_message>.*)'
    #           source: output
    #       - labels:
    #           stream:
    #           container_name:
    #           fluentd_time:
    #           fluentd_label:
    #           fluentd_message:
    #       # - json:
    #       #     expressions:
    #       #       log_line: fluentd_message
    #       #     source: fluentd_message
    #       # - replace:
    #       #     expression: ".*\\r.*"
    #       #     replace: ""
    #       # take string encoded part, and turn it into json
    #       # - replace:
    #       #     expression: ".*null.*"
    #       #     replace: ""
    #       - replace:
    #           expression: "(.+)"
    #           replace: "{{fromJson .Value}}"
    #           source: fluentd_message
    #       - output:
    #           source: output

  # # Name to identify this scrape config in the Promtail UI.
  # job_name: <string>

  # # Describes how to transform logs from targets.
  # [pipeline_stages: <pipeline_stages>]

  # # Describes how to scrape logs from the journal.
  # [journal: <journal_config>]

  # # Describes how to receive logs from syslog.
  # [syslog: <syslog_config>]

  # # Describes how to receive logs via the Loki push API, (e.g. from other Promtails or the Docker Logging Driver)
  # [loki_push_api: <loki_push_api_config>]

  # # Describes how to scrape logs from the Windows event logs.
  # [windows_events: <windows_events_config>]

  # # Describes how to fetch logs from Kafka via a Consumer group.
  # [kafka: <kafka_config>]

  # # Describes how to relabel targets to determine if they should
  # # be processed.
  # relabel_configs:
  #   - [<relabel_config>]

  # # Static targets to scrape.
  # static_configs:
  #   - [<static_config>]

  # # Files containing targets to scrape.
  # file_sd_configs:
  #   - [<file_sd_configs>]

  # # Describes how to discover Kubernetes services running on the
  # # same host.
  # kubernetes_sd_configs:
  #   - [<kubernetes_sd_config>]

  # # Describes how to use the Consul Catalog API to discover services registered with the
  # # consul cluster.
  # consul_sd_configs:
  #   [ - <consul_sd_config> ... ]

  # # Describes how to use the Consul Agent API to discover services registered with the consul agent
  # # running on the same host as Promtail.
  # consulagent_sd_configs:
  #   [ - <consulagent_sd_config> ... ]

# metrics:
#       wal_directory: /tmp/agent
#       wal_cleanup_age: 12h
#       wal_cleanup_period: 30m
#       global:
#         scrape_interval: 1m
#         scrape_timeout: 15s
#         external_labels:
#           miner: boss-monitor
#         remote_write:
#           - url: "http://192.168.1.98:8086"
#             # basic_auth:
#             #   username: "{{ target_prometheus_username }}"
#             #   password: "{{ target_prometheus_password }}"
#       configs:
#         - name: cadvisor
#           scrape_configs:
#             - job_name: cadvisor
#               scrape_interval: 20s
#               scrape_timeout: 10s
#               static_configs:
#                 # - targets: ["cadvisor:8081"]
#                 - targets: ["192.168.1.98:8081"]
#               relabel_configs:
#                 - source_labels: [__address__]
#                   regex: ".*"
#                   target_label: instance
#                   replacement: boss-monitor
#                 - source_labels: [__address__]
#                   regex: ".*"
#                   target_label: node
#                   replacement: boss-monitor
#         - name: docker-daemon
#           scrape_configs:
#             - job_name: docker-daemon
#               scrape_interval: 20s
#               scrape_timeout: 10s
#               static_configs:
#                 - targets: ["host.docker.internal:9323"]
#               relabel_configs:
#                 - source_labels: [__address__]
#                   regex: ".*"
#                   target_label: instance
#                   replacement: boss-monitor
#                 - source_labels: [__address__]
#                   regex: ".*"
#                   target_label: node
#                   replacement: boss-monitor

# integrations:
#   node_exporter:
#     enabled: true
#     rootfs_path: /
#     sysfs_path: /sys
#     procfs_path: /proc
#     relabel_configs:
#     - source_labels: [__address__]
#       regex: ".*"
#       target_label: instance
#       replacement: boss-monitor
#     - source_labels: [__address__]
#       regex: ".*"
#       target_label: node
#       replacement: boss-monitor
