# version: '3.8'

networks:
  loki:

# Since only root has access to /var/lib/docker and I'm running the Grafana agent under its own user on the host itself, changing the permissions to that directory seemed like a bad idea to me. After a bit of research I figured out how to make this work using the journald driver, which works nicely.
# SOURCE: https://gist.github.com/ruanbekker/c6fa9bc6882e6f324b4319c5e3622460?permalink_comment_id=4009155#gistcomment-4009155
{% raw %}
x-logging:
  &default-logging
  driver: "journald"
  options:
    tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"

# for the unifipoller bits
# https://github.com/unpoller/unpoller/blob/master/init/docker/docker-compose.yml
volumes:
    prometheus_data: {}
    grafana_data: {}
    netdataconfig:
    netdatalib:
    netdatacache:
    influxdb-storage:
    chronograf-storage:
    grafana-storage:
    alertmanager-data:
    pushgateway-data:
    loki:
    pihole_etc:
    pihole_dnsmasq:
    portainer_data:
{% endraw %}

services:
{% if traefik_feature_flag %}
  # SOURCE: https://doc.traefik.io/traefik/user-guides/docker-compose/basic-example/
  # SOURCE: https://doc.traefik.io/traefik/user-guides/docker-compose/basic-example/
  traefik:
    image: "traefik:v2.10.4"
    container_name: "traefik"
    # environment:
    # # SOURCE: https://community.traefik.io/t/docker-compose-static-config-issue/10987
    command:
      - "--log.level=DEBUG"
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
      - "--entrypoints.websecure.address=:443"
      - "--entrypoints.traefik.address=:8989"
      - "--metrics.prometheus=true"
      - "--metrics.prometheus.addrouterslabels=true"
      - "--api=true"
      - "--api.insecure=true"
      - "--providers.docker.network=loki"
      - "--ping=true"
      - "--ping.entrypoint=traefik"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.file.directory=/etc/traefik/dynamic"
      - "--providers.file.filename=/etc/traefik/dynamic/dynamic.yaml"
      - "--providers.file.watch=true"
      - "--configFile=/etc/traefik/traefik.yaml"
    ports:
      - "80:80"
      - "443:443"
      - "8989:8989"
      - "8082:8082"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - ./traefik/traefik.yaml:/etc/traefik/traefik.yaml:ro
      - ./traefik/dynamic:/etc/traefik/dynamic
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.traefik.rule=Host(`traefik.{{ fqdn }}`)"
      - "traefik.http.routers.traefik.service=api@internal"
      - "traefik.http.routers.traefik.entrypoints=web"
      - "traefik.http.services.traefik.loadbalancer.server.port=8989"
      - "traefik.port=8989"
      - "traefik.docker.network=loki"
    networks:
      loki: null
    # - loki
    extra_hosts:
      - host.docker.internal:172.17.0.1
    restart: unless-stopped
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}
{% endif %}

# SEE: https://github.com/pi-hole/pi-hole/issues/4816#issuecomment-1883994394
# SEE: https://github.com/pi-hole/pi-hole/issues/5635
{% if portainer_feature_flag %}
  portainer:
    image: "portainer/portainer-ce:2.20.3"
    command: -H unix:///var/run/docker.sock --admin-password $$2y$$05$$cQ4zB2SEdP4U3kkNhUV.Gu/xPdE4wSKEo1ncBFfKeERMI6IiXbg8y --http-enabled true
    container_name: "portainer"
    ports:
      # - "8000:8000/tcp"
      - "0.0.0.0:49443:9443"
      - "0.0.0.0:49000:9000"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.portainer.rule=Host(`portainer.{{ fqdn }}`)"
      - "traefik.http.routers.portainer.entrypoints=web"
      - "traefik.http.routers.portainer.service=portainer"
      - "traefik.http.services.portainer.loadbalancer.server.port=9443"
      - "traefik.port=49443"
    expose:
    - 49443
    - 49000
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
      - 'portainer_data:/data'
    restart: always
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}
{% endif %}

  loki-gateway:
    image: nginx:1.25.3-perl
    container_name: "loki-gateway"
    depends_on:
      - 'loki-read'
      - 'loki-write'
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
    restart: unless-stopped
    ports:
      - "8080:80"
      - "3100:3100"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.loki-gateway-http.rule=Host(`loki-gateway.{{ fqdn }}`)"
      - "traefik.http.routers.loki-gateway-http.entrypoints=web"
      - "traefik.http.routers.loki-gateway-http.service=loki-gateway-http"
      - "traefik.http.services.loki-gateway-http.loadbalancer.server.port=80"
      - "traefik.port=8080"
    networks:
      - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  # SOURCE: https://github.com/robozmey/roomkn-sre/blob/179ec407ae7e6ddf2135af8d2d3811950448ec85/docker-compose.yml#L82
  nginx-exporter:
    image: nginx/nginx-prometheus-exporter:1.0.0
    container_name: "nginx-exporter"
    depends_on:
      - 'loki-gateway'
    restart: unless-stopped
    command:
      - '--nginx.scrape-uri=http://loki-gateway/nginx_status'
    ports:
      - "9113:9113"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.nginx-exporter-http.rule=Host(`nginx-exporter.{{ fqdn }}`)"
      - "traefik.http.routers.nginx-exporter-http.entrypoints=web"
      - "traefik.http.routers.nginx-exporter-http.service=nginx-exporter-http"
      - "traefik.http.services.nginx-exporter-http.loadbalancer.server.port=9113"
      - "traefik.port=9113"
    networks:
      - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  # SOURCE: https://github.com/robozmey/roomkn-sre/blob/179ec407ae7e6ddf2135af8d2d3811950448ec85/docker-compose.yml#L82
  speedtest-exporter:
    image: miguelndecarvalho/speedtest-exporter
    container_name: "speedtest-exporter"
    restart: unless-stopped
    ports:
      - "9798:9798"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.speedtest-exporter-http.rule=Host(`speedtest-exporter.{{ fqdn }}`)"
      - "traefik.http.routers.speedtest-exporter-http.entrypoints=web"
      - "traefik.http.routers.speedtest-exporter-http.service=speedtest-exporter-http"
      - "traefik.http.services.speedtest-exporter-http.loadbalancer.server.port=9798"
      - "traefik.port=9798"
    networks:
      - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  # Since the Loki containers are running as user 10001 and the mounted data volume is owned by root,
  # Loki would not have permissions to create the directories.
  # Therefore the init container changes permissions of the mounted directory.
  init:
    image: grafana/loki:2.8.3
    user: root
    entrypoint:
      - "chown"
      # - "10001:10001"
      - "1000:1000"
      - "/loki"
    volumes:
      - ./loki:/loki
    networks:
      - loki

  minio:
    image: minio/minio:RELEASE.2023-06-29T05-12-28Z
    container_name: minio
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /data/loki-data && \
        mkdir -p /data/loki-ruler &&
        minio server /data --address ":9000" --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=loki
      - MINIO_ROOT_PASSWORD=supersecret
      - MINIO_PROMETHEUS_AUTH_TYPE=public
      - MINIO_UPDATE=off
      - MINIO_PROMETHEUS_URL=http://prometheus:9090
      - MINIO_PROMETHEUS_JOB_ID=minio-cluster
      - MINIO_BROWSER=on
      # - MINIO_ACCESS_KEY=admin
      # - MINIO_SECRET_KEY=password
    ports:
      - "9000:9000"
      - "9001:9001"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.minio-http.rule=Host(`minio.{{ fqdn }}`)"
      - "traefik.http.routers.minio-http.entrypoints=web"
      - "traefik.http.routers.minio-http.service=minio-http"
      - "traefik.http.services.minio-http.loadbalancer.server.port=9000"
      - "traefik.port=9000"
    volumes:
      - ./.data/minio:/data
    networks:
      - loki
    restart: unless-stopped

{% if log_generator_feature_flag %}
  # for testing purposes only, disable in production
  log-generator:
    image: mingrammer/flog
    command:
      - --loop
      - --format=json
      - --number=10 # number of log lines to generate per second
      - --delay=100ms # delay between log lines
      - --output=/var/log/generated-logs.txt
      - --overwrite
      - --type=log
    volumes:
      - ./loki/:/var/log/
{% endif %}

  whoami:
    image: "traefik/whoami:v1.8.0"
    container_name: "whoami"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.whoami.rule=Host(`whoami.{{ fqdn }}`)"
      - "traefik.http.routers.whoami.entrypoints=web"
      - "traefik.http.routers.whoami.service=whoami"
      - "traefik.http.services.whoami.loadbalancer.server.port=10080"
      - "traefik.port=10080"
    expose:
      - 10080
    environment:
    #- TZ=UTC
    - WHOAMI_PORT_NUMBER=10080
    - WHOAMI_NAME=whoami
    ports:
    - 10080:10080
    networks:
    - loki
    restart: unless-stopped
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

{% if weave_scope_feature_flag %}
  scope:
    image: "weaveworks/scope:1.13.2"
    network_mode: "host"
    pid: "host"
    privileged: true
    labels:
      - "works.weave.role=system"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:rw"
    command:
      - "--probe.docker=true"
      - "--weave=false"
      - "--app.http.address=:4041"
    container_name: scope
    cap_add:
      - NET_ADMIN # Required if you are using Pi-hole as your DHCP server, else not needed
    restart: unless-stopped
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}
{% endif %}

# SEE: https://github.com/pi-hole/pi-hole/issues/4816#issuecomment-1883994394
# SEE: https://github.com/pi-hole/pi-hole/issues/5635
{% if pihole_feature_flag %}
  pihole:
    build:
      context: ./pihole
    # image: "pihole/pihole:2023.11.0"
    # For DHCP it is recommended to remove these ports and instead add: network_mode: "host"
    ports:
      - "53:53/tcp"
      - "53:53/udp"
      # - "67:67/udp" # Only required if you are using Pi-hole as your DHCP server
      - "81:80/tcp"
    container_name: pihole
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.pihole.rule=Host(`pihole.{{ fqdn }}`)"
      - "traefik.http.routers.pihole.entrypoints=web"
      - "traefik.http.routers.pihole.service=pihole"
      - "traefik.http.services.pihole.loadbalancer.server.port=80"
      - "traefik.port=80"
    # Volumes store your data between container upgrades
    expose:
    - 81
    volumes:
      - 'pihole_etc:/etc/pihole'
      - 'pihole_dnsmasq:/etc/dnsmasq.d'
    #   https://github.com/pi-hole/docker-pi-hole#note-on-capabilities
    cap_add:
      - NET_ADMIN # Required if you are using Pi-hole as your DHCP server, else not needed
      # - CAP_NET_BIND_SERVICE
      # - CAP_NET_RAW
      # - CAP_NET_ADMIN
      # - CAP_SYS_NICE
      # - CAP_CHOWN
    restart: unless-stopped
    # NOTE: https://github.com/pi-hole/docs/blob/release/v6.0/docs/ftldns/configfile.md#local_ipv4-unset-by-default-pr-1293-local_ipv4-data-toc-labelforce-local-a-reply
    environment:
    # SOURCE: https://github.com/ElPoshoX/pihole-dns-stack/blob/89e05bf357b56132ff7a93ea7c4aeb742aa026aa/docker-compose.yml#L45
    # Customize the options with which dnsmasq gets started. e.g. no-daemon -- --dns-forward-max 300 to increase max. number of concurrent dns queries on high load setups.
    - FTL_CMD="no-daemon -- --dns-forward-max 5096 --min-cache-ttl 300"
    - QUERY_LOGGING=true
    - TZ=America/New_York
    - WEBPASSWORD=raspberry
    # Use the Pi-hole web UI to change the DNS settings Interface listening behavior to "Listen on all interfaces, permit all origins", if using Docker's default bridge network setting. (This can also be achieved by setting the environment variable DNSMASQ_LISTENING to all)
    # - DNSMASQ_USER=root
    - DNSMASQ_LISTENING=all
    # - PIHOLE_UID=0
    # Set the cache size for dnsmasq. Useful for increasing the default cache size or to set it to 0. Note that when DNSSEC is "true", then this setting is ignored.
    - CUSTOM_CACHE_SIZE=10000
    - PIHOLE_DNS_=127.0.0.1#5335;1.1.1.2;1.0.0.2
    - NETWORK_ACCESS=internal
    - VIRTUAL_HOST=pi.hole
    - PROXY_LOCATION=pi.hole
    # Set to your server's LAN IP, used by web block modes.
    - FTLCONF_LOCAL_IPV4={{ prometheus_server_ip }}
    # - FTLCONF_RATE_LIMIT=0/0
    # SOURCE: https://docs.pi-hole.net/ftldns/configfile/#rate_limit
    - FTLCONF_RATE_LIMIT=5000/60
    # - FTLCONF_RATE_LIMIT=0/0
    # - LOCAL_IPV4={{ prometheus_server_ip }}
    - WEBLOGS_STDOUT=1
    - DHCP_ACTIVE=false
    - DNSSEC=true
    # Set a password to access the web interface. Not setting one will result in a random password being assigned
    - FTLCONF_dns_upstreams=127.0.0.1#5335;1.1.1.2;1.0.0.2
    - FTLCONF_webserver_api_password=raspberry
    - FTLCONF_dns_dnssec=true
    - TAIL_FTL_LOG=1
    - FTLCONF_dns_listeningMode=all
    - ADDITIONAL_PACKAGES="systemd vim curl"
    - DEBUG_ALL=true
    - DEBUG_DATABASE=true
    - DEBUG_NETWORKING=true
    - DEBUG_EDNS0=true
    - DEBUG_QUERIES=true
    # SOCKET_LISTENING=localonly|all socket_listening data-toc-label='Socket Listening'
    # Listen only for local socket connections or permit all connections
    - SOCKET_LISTENING=all
    - PH_VERBOSE=4
    - FTLCONF_DEBUG_CAPS=true

    dns:
      - "127.0.0.1"
      - "1.1.1.2"
      - "1.0.0.2"
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  pihole-exporter:
    image: "ekofr/pihole-exporter:latest"
    # For DHCP it is recommended to remove these ports and instead add: network_mode: "host"
    hostname: 'pihole-exporter'
    ports:
      - "9617:9617/tcp"
    container_name: pihole-exporter
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.pihole-exporter.rule=Host(`pihole-exporter.{{ fqdn }}`)"
      - "traefik.http.routers.pihole-exporter.entrypoints=web"
      - "traefik.http.routers.pihole-exporter.service=pihole-exporter"
      - "traefik.http.services.pihole-exporter.loadbalancer.server.port=9617"
      - "traefik.port=9617"
      # - "traefik.docker.network=loki"
    # Volumes store your data between container upgrades
    expose:
    - 9617
    restart: unless-stopped
    environment:
    - TZ=America/New_York
    - PORT=9617
    - PIHOLE_PASSWORD=raspberry
    - PIHOLE_HOSTNAME=pihole
    - PIHOLE_PORT=80
    # - PIHOLE_PROTOCOL="http"
    networks:
    - loki
    depends_on:
      - pihole
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}
{% endif %}

  influxdb:
    restart: always
    image: influxdb:1.8
    container_name: influxdb
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.influxdb.rule=Host(`influxdb.{{ fqdn }}`)"
    - "traefik.http.routers.influxdb.entrypoints=web"
    - "traefik.http.routers.influxdb.service=influxdb"
    - "traefik.http.services.influxdb.loadbalancer.server.port=8086"
    - "traefik.port=8086"
    ports:
      - '8086:8086'
    volumes:
      - influxdb-storage:/var/lib/influxdb
    environment:
      - INFLUXDB_DB=${INFLUXDB_DB}
      - INFLUXDB_HTTP_AUTH_ENABLED=${INFLUXDB_HTTP_AUTH_ENABLED}
      - INFLUXDB_ADMIN_USER=${INFLUXDB_ADMIN_USER}
      - INFLUXDB_ADMIN_PASSWORD=${INFLUXDB_ADMIN_PASSWORD}
      # SOURCE: https://docs.influxdata.com/influxdb/v1.8/administration/config/
      - INFLUXDB_META_LOGGING_ENABLED=1
      - INFLUXDB_HTTP_ENABLED=1
      - INFLUXDB_HTTP_LOG_ENABLED=1
      # - INFLUXDB_HTTP_AUTH_ENABLED=0
      - INFLUXDB_LOGGING_LEVEL={{ influxdb_log_level }}
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_ADMIN_USER}
      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_ADMIN_PASSWORD}
      - DOCKER_INFLUXDB_INIT_ORG=${INFLUXDB_ORG}
      - DOCKER_INFLUXDB_INIT_BUCKET=${INFLUXDB_BUCKET}
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=${INFLUXDB_ADMIN_TOKEN}
      # CREATE DATABASE unifi
      # USE unifi
      # CREATE USER unifipoller WITH PASSWORD 'unifipoller' WITH ALL PRIVILEGES
      # GRANT ALL ON unifi TO unifipoller
      # exit
      # DOCKER_INFLUXDB_INIT_USERNAME: The username to set for the system's initial super-user (Required).
      # DOCKER_INFLUXDB_INIT_PASSWORD: The password to set for the system's inital super-user (Required).
      # DOCKER_INFLUXDB_INIT_ORG: The name to set for the system's initial organization (Required).
      # DOCKER_INFLUXDB_INIT_BUCKET: The name to set for the system's initial bucket (Required).
      # DOCKER_INFLUXDB_INIT_RETENTION: The duration the system's initial bucket should retain data. If not set, the initial bucket will retain data forever.
      # DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: The authentication token to associate with the system's initial super-user. If not set, a token will be auto-generated by the system.
      # - DOCKER_INFLUXDB_INIT_MODE=setup
      # - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_ADMIN_USER}
      # - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_ADMIN_PASSWORD}
      # - DOCKER_INFLUXDB_INIT_ORG=unpoller
      # - DOCKER_INFLUXDB_INIT_BUCKET=unpoller
      # - DOCKER_INFLUXDB_INIT_RETENTION=1w
      # - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=unpollersecret
      #- TZ=UTC
    env_file:
      - ./env
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  chronograf:
    restart: always
    image: chronograf:latest
    container_name: chronograf
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.chronograf.rule=Host(`chronograf.{{ fqdn }}`)"
    - "traefik.http.routers.chronograf.entrypoints=web"
    - "traefik.http.routers.chronograf.service=chronograf"
    - "traefik.http.services.chronograf.loadbalancer.server.port=8888"
    - "traefik.port=8888"
    ports:
      - '8888:8888'
    volumes:
      - chronograf-storage:/var/lib/chronograf
    depends_on:
      - influxdb
    environment:
      - INFLUXDB_URL=http://influxdb:8086
      # - INFLUXDB_URL=${INFLUXDB_URL}
      - INFLUXDB_USERNAME=${INFLUXDB_ADMIN_USER}
      - INFLUXDB_PASSWORD=${INFLUXDB_ADMIN_PASSWORD}
      #- TZ=UTC
    env_file:
      - ./env
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  # docker pull prom/prometheus:v2.31.1
  prometheus:
    image: prom/prometheus:v2.31.1
    container_name: prometheus
    expose:
    - 9090
    tty: true
    stdin_open: true
    volumes:
      - ./prometheus/:/etc/prometheus/
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.listen-address=0.0.0.0:9090'
      - '--log.level={{ prometheus_log_level }}'
      - '--enable-feature=remote-write-receiver'
      - '--query.lookback-delta=30s'
    ports:
      - 9092:9090
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.prometheus.rule=Host(`prometheus.{{ fqdn }}`)"
      - "traefik.http.routers.prometheus.entrypoints=web"
      - "traefik.http.routers.prometheus.service=prometheus"
      - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
      - "traefik.port=9090"
    links:
{% if cadvisor_feature_flag %}
      - cadvisor:cadvisor
{% endif %}
      - alertmanager:alertmanager
      - loki-gateway:loki-gateway
      - pihole-exporter:pihole-exporter
    depends_on:
{% if cadvisor_feature_flag %}
      - cadvisor
{% endif %}
      - alertmanager
      - loki-gateway
      - pihole-exporter
      - pushgateway
    restart: always

    # environment:
    #- TZ=UTC
    # SEE: https://stackoverflow.com/questions/31324981/how-to-access-host-port-from-docker-container/43541732#43541732
    # https://stackoverflow.com/questions/56909896/prometheus-in-docker-container-cannot-scrape-target-on-host/56910057
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}


  # docker pull prom/pushgateway:v1.8.0
  pushgateway:
    image: prom/pushgateway:v1.8.0
    container_name: pushgateway
    expose:
    - 9091
    tty: true
    stdin_open: true
    restart: always
    ports:
      - 0.0.0.0:9091:9091
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.pushgateway.rule=Host(`pushgateway.{{ fqdn }}`)"
      - "traefik.http.routers.pushgateway.entrypoints=web"
      - "traefik.http.routers.pushgateway.service=pushgateway"
      - "traefik.http.services.pushgateway.loadbalancer.server.port=9091"
      - "traefik.port=9091"
    volumes:
      - pushgateway-data:/data
    command:
      - '--log.level={{ pushgateway_log_level }}'
      - '--web.listen-address=0.0.0.0:9091'
      # - '--web.listen-address=0.0.0.0:9091'
      - '--web.enable-admin-api'
    # environment:
    #- TZ=UTC
    # SEE: https://stackoverflow.com/questions/31324981/how-to-access-host-port-from-docker-container/43541732#43541732
    # https://stackoverflow.com/questions/56909896/pushgateway-in-docker-container-cannot-scrape-target-on-host/56910057
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.node-exporter.rule=Host(`node-exporter.{{ fqdn }}`)"
    - "traefik.http.routers.node-exporter.entrypoints=web"
    - "traefik.http.routers.node-exporter.service=node-exporter"
    - "traefik.http.services.node-exporter.loadbalancer.server.port=9100"
    - "traefik.port=9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      # - --collector.filesystem.ignored-mount-points
      # - "^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)"
      -  '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      # - '--collector.thermal_zone-exclude'
    expose:
    - 9100
    ports:
      - 9100:9100
    restart: always
    deploy:
      mode: global
    # environment:
    #- TZ=UTC
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  alertmanager:
    image: prom/alertmanager
    container_name: alertmanager
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.alertmanager.rule=Host(`alertmanager.{{ fqdn }}`)"
    - "traefik.http.routers.alertmanager.entrypoints=web"
    - "traefik.http.routers.alertmanager.service=alertmanager"
    - "traefik.http.services.alertmanager.loadbalancer.server.port=9093"
    - "traefik.port=9093"
    tty: true
    stdin_open: true
    expose:
    - 9093
    ports:
      - 0.0.0.0:9093:9093
    volumes:
      - ./alertmanager/:/etc/alertmanager/
      - alertmanager-data:/data
    restart: always
    depends_on:
    - alertmanager-telegram
    links:
    - alertmanager-telegram:alertmanager-telegram
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
      - '--log.level={{ alertmanager_log_level }}'
    # environment:
    #- TZ=UTC
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}


  alertmanager-telegram:
    build:
      context: ./alertmanager_telegram
    # image: ghcr.io/janw/alertmanager-telegram:latest
    container_name: alertmanager-telegram
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.alertmanager-telegram.rule=Host(`alertmanager-telegram.{{ fqdn }}`)"
    - "traefik.http.routers.alertmanager-telegram.entrypoints=web"
    - "traefik.http.routers.alertmanager-telegram.service=alertmanager-telegram"
    - "traefik.http.services.alertmanager-telegram.loadbalancer.server.port=8585"
    - "traefik.port=8585"
    tty: true
    stdin_open: true
    expose:
    - 8585
    ports:
      - "8585:8080"
    restart: always
    env_file:
      - ./env
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

{% if cadvisor_feature_flag %}
  cadvisor:
    # SOURCE: https://github.com/rafaribe/home-ops/blob/d9e283fd3ddc42a9891c8a12fe82fa128657798a/provision/ansible/backup-server/roles/syncthing/templates/agent.yml
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: cadvisor
    privileged: true
    userns_mode: "host"
    pid: "host"
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.cadvisor.rule=Host(`cadvisor.{{ fqdn }}`)"
    - "traefik.http.routers.cadvisor.entrypoints=web"
    - "traefik.http.routers.cadvisor.service=cadvisor"
    - "traefik.http.services.cadvisor.loadbalancer.server.port=8081"
    - "traefik.port=8081"
    volumes:
        - /:/rootfs:ro
        - /var/run:/var/run:ro
        - /sys:/sys:ro
        - /var/lib/docker/:/var/lib/docker:ro
        - /dev/disk/:/dev/disk:ro
        - /etc/machine-id/:/etc/machine-id:ro
        # SOURCE: https://dev.to/cloudx/taming-cadvisors-high-cpu-usage-1nm5
        - /sys/fs/cgroup:/cgroup:ro
        - /etc/localtime:/etc/localtime:ro
    devices:
        - /dev/kmsg:/dev/kmsg:ro
    ports:
        - "8081:8081"
    expose:
      - 8081
    restart: always
    entrypoint:
      - /usr/bin/cadvisor
      # - --v=6
      - '--max_procs=2'
      - '--listen_ip=0.0.0.0'
      - '--port=8081'
      - '--logtostderr'
      # - '--enable_load_reader=true'
      - '--machine_id_file="/etc/machine-id"'
      - '--enable_metrics=advtcp,app,cpu,cpu_topology,cpuset,disk,diskIO,hugetlb,memory,memory_numa,network,oom_event,percpu,perf_event,process,resctrl,sched,tcp,udp'
      # - '--disable_metrics=referenced_memory,cpuLoad'
      # - "--housekeeping_interval=30s"
      # - "--max_housekeeping_interval=35s"
      # - "--event_storage_event_limit=default=0"
      # - "--event_storage_age_limit=default=0"
      # - "--store_container_labels=false"
      # - "--whitelisted_container_labels=io.kubernetes.container.name,io.kubernetes.pod.name,io.kubernetes.pod.namespace,io.kubernetes.pod.uid"
      # - "--global_housekeeping_interval=30s"
      # - "--event_storage_event_limit=default=0"
      # - "--event_storage_age_limit=default=0"
      # - "--disable_metrics=percpu,process,sched,tcp,udp,diskIO,disk,network"
      # - "--allow_dynamic_housekeeping=true"
      # - "--storage_duration=1m0s"
      # SOURCE: https://dev.to/cloudx/taming-cadvisors-high-cpu-usage-1nm5
      - "--housekeeping_interval=30s"
      - "--docker_only=true"
      - "--disable_metrics=percpu,sched,tcp,udp,disk,diskIO,hugetlb,referenced_memory,cpu_topology,resctrl,cpuLoad"
    env_file:
      - ./env
    # devices:
    # - /dev/kmsg:/dev/kmsg
    # environment:
    #- TZ=UTC
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}
{% endif %}

  blackbox:
    image: prom/blackbox-exporter
    privileged: true
    container_name: blackbox
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.blackbox.rule=Host(`blackbox.{{ fqdn }}`)"
    - "traefik.http.routers.blackbox.entrypoints=web"
    - "traefik.http.routers.blackbox.service=blackbox"
    - "traefik.http.services.blackbox.loadbalancer.server.port=9115"
    - "traefik.port=9115"
    tty: true
    stdin_open: true
    ports:
    - "9115:9115/tcp"
    - "9115:9115/udp"
    expose:
    - 9115
    volumes:
    - ./blackbox/config:/config
    command:
      - '--config.file=/config/blackbox.yml'
      - '--web.listen-address=:9115'
    cap_add:
      - NET_ADMIN # Required if you are using Pi-hole as your DHCP server, else not needed
    restart: always
    deploy:
      mode: global
    #environment:
    #- TZ=UTC
    networks:
    - loki
    depends_on:
    - pihole
    dns:
      - "192.168.3.16"
      - "1.1.1.2"
      - "1.0.0.2"

{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  unifi-poller:
    restart: always
    # 2023: Use -> ghcr.io/unpoller/unpoller:${POLLER_TAG}
    image: golift/unifi-poller:${POLLER_TAG}
    ports:
      - "9130:9130/tcp"
      - "9130:9130/udp"
      - "37288:37288"
    expose:
    - 9130
    container_name: unifi-poller
    tty: true
    stdin_open: true
    volumes:
      - ./unpoller/up.conf:/etc/unpoller/up.conf
    env_file:
      - ./env
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.unifipoller.rule=Host(`unifi-poller.{{ fqdn }}`)"
    - "traefik.http.routers.unifipoller.entrypoints=web"
    - "traefik.http.routers.unifipoller.service=unifipoller"
    - "traefik.http.services.unifipoller.loadbalancer.server.port=37288"
    - "traefik.port=37288"
    depends_on:
      - grafana
      - influxdb
      - chronograf
    environment:
    - UP_WEBSERVER_ENABLE=true
    - UP_INFLUXDB_DB=${INFLUXDB_DB}
    - UP_INFLUXDB_USER=${INFLUXDB_ADMIN_USER}
    - UP_INFLUXDB_PASS=${INFLUXDB_ADMIN_PASSWORD}
    - UP_INFLUXDB_ORG=${INFLUXDB_ORG}
    - UP_INFLUXDB_BUCKET=${INFLUXDB_BUCKET}
    - UP_INFLUXDB_AUTH_TOKEN=${INFLUXDB_ADMIN_TOKEN}
    - UP_INFLUXDB_URL=http://influxdb:8086
    - UP_UNIFI_DEFAULT_USER=${UNIFI_USER}
    - UP_UNIFI_DEFAULT_PASS=${UNIFI_PASS}
    - UP_UNIFI_DEFAULT_URL=${UNIFI_URL}
    - UP_POLLER_DEBUG=${POLLER_DEBUG}
    - UP_UNIFI_DEFAULT_SAVE_DPI=${POLLER_SAVE_DPI}
    - UP_PROMETHEUS_NAMESPACE=unifipoller
    networks:
    - loki


  loki-read:
    user: "1000"
    image: grafana/loki:2.8.3
    volumes:
      # - ./config:/etc/loki/
      # - ./loki/etc/loki:/etc/loki/
      - ./loki/etc/loki:/loki:rw
      - ./rules:/loki/rules:ro
    ports:
      # - 3101:3100
      # - 7946
      - "9095"
      #- "3101:3100"
      - "3100"
      - "7946"
      # uncomment to use interactive debugging
      # - "40000-40002:40000" # # makes the replicas available on ports 40000, 40001, 40002
    #cap_add:
    #  - SYS_PTRACE
    #security_opt:
    #  - apparmor=unconfined
    command: "-config.file=/loki/loki-config.yaml -log.level={{ loki_log_level }} -target=read -legacy-read-mode=false"
    env_file:
      - ./env
    networks:
      - loki
    depends_on:
      - minio
    restart: always
    deploy:
      mode: replicated
      replicas: 3
    # only needed for interactive debugging with dlv
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  loki-write:
    user: "1000"
    image: grafana/loki:2.8.3
    volumes:
      # - ./config:/etc/loki/
      - ./loki/etc/loki:/loki:rw
    ports:
      - "9095"
      #- "3102:3100"
      - "3100"
      - "7946"
      # uncomment to use interactive debugging
      # - "50000-50002:40000" # makes the replicas available on ports 50000, 50001, 50002
    #cap_add:
    #  - SYS_PTRACE
    #security_opt:
    #  - apparmor=unconfined
    # command: "-config.file=/loki/loki-config.yaml -log.level={{ loki_log_level }} -target=write -frontend.downstream-url=http://loki-gateway:3100 -querier.frontend-address=http://loki-write:9095"
    command: "-config.file=/loki/loki-config.yaml -log.level={{ loki_log_level }} -target=write -frontend.downstream-url=http://loki-gateway"
    env_file:
      - ./env
    networks:
      - loki
    depends_on:
      - minio
    restart: always
    deploy:
      mode: replicated
      replicas: 3
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

  loki-backend:
    user: "1000"
    image: grafana/loki:2.8.3
    volumes:
      # - ./config:/etc/loki/
      - ./loki/etc/loki:/loki:rw
    ports:
      - "9095"
      #- "3102:3100"
      - "3100"
      - "7946"
      # uncomment to use interactive debugging
      # - "50000-50002:40000" # makes the replicas available on ports 50000, 50001, 50002
    #cap_add:
    #  - SYS_PTRACE
    #security_opt:
    #  - apparmor=unconfined
    # command: "-config.file=/loki/loki-config.yaml -log.level={{ loki_log_level }} -target=write -frontend.downstream-url=http://loki-gateway:3100 -querier.frontend-address=http://loki-write:9095"
    command: "-config.file=/loki/loki-config.yaml -log.level={{ loki_log_level }} -target=backend -legacy-read-mode=false"
    env_file:
      - ./env
    networks:
      - loki
    depends_on:
      - minio
    restart: always
    deploy:
      mode: replicated
      replicas: 3
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

#   loki:
#     restart: always
#     image: grafana/loki:2.8.3
#     ports:
#       - "3100:3100/tcp"
#       - "9096:9096"
#     container_name: loki
#     tty: true
#     stdin_open: true
#     env_file:
#       - ./env
#     volumes:
#     - ./loki/etc/loki:/loki
#     labels:
#     - "traefik.enable=true"
#     - "traefik.http.routers.loki.rule=Host(`loki.{{ fqdn }}`)"
#     - "traefik.http.routers.loki.entrypoints=web"
#     - "traefik.http.services.loki.loadbalancer.server.port=3100"
#     - "traefik.http.services.loki.loadbalancer.server.port=3100"
#     command: -config.file=/loki/loki-config.yaml
#     networks:
#     - loki
{% raw %}
#     logging:
#       driver: json-file
#       options:
#         tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}

{% if promtail_feature_flag %}
  promtail:
    # SOURCE: https://github.com/gilmrt/docker-compose/blob/5d8d7b3746fba48ba5f559f9913e56ae3d881eee/metrics/docker-compose.yml
    container_name: promtail
    image: grafana/promtail:2.8.3
    restart: always
    depends_on:
      - 'loki-gateway'
      - 'loki-read'
      - 'loki-write'
      - 'loki-backend'
    volumes:
      # - /var/log:/var/log:ro
      - ./promtail/promtail-gateway.yaml:/etc/promtail/promtail-gateway.yaml:ro
      # - ./promtail/promtail-debug.yaml:/etc/promtail/promtail-debug.yaml:rw
      # - /var/log/journal/:/var/log/journal/:ro
      # - /run/log/journal/:/run/log/journal/:ro
      - /etc/machine-id:/etc/machine-id:ro
      - ./promtail/var/run/promtail:/var/run/promtail
      # to read container labels and logs
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      # - /var/lib/docker/containers:/var/lib/docker/containers:ro
      # - /home/pi/dev/bossjones/elk-docker/rsyslog-conf/log:/log
      # so we can get generated logs
      - ./loki/:/var/log/:ro
    ports:
      - "9080:9080"
    expose:
    - 9080
    command:
    - '-config.file=/etc/promtail/promtail-gateway.yaml'
    # - '-print-config-stderr'
    # - '-log-config-reverse-order'
    - '--inspect'
    # environment:
    #- TZ=UTC
    tty: true
    stdin_open: true
    env_file:
      - ./env
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.promtail.rule=Host(`promtail.{{ fqdn }}`)"
    - "traefik.http.routers.promtail.entrypoints=web"
    - "traefik.http.routers.promtail.service=promtail"
    - "traefik.http.services.promtail.loadbalancer.server.port=9080"
    - "traefik.port=9080"
    # depends_on:
    # - loki
    networks:
    - loki
{% endif %}

  grafana:
    image: grafana/grafana:10.0.1
    container_name: grafana
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.grafana.rule=Host(`grafana.{{ fqdn }}`)"
    - "traefik.http.routers.grafana.entrypoints=web"
    - "traefik.http.routers.grafana.service=grafana"
    - "traefik.http.services.grafana.loadbalancer.server.port=3000"
    - "traefik.port=3000"
    depends_on:
      - prometheus
      - loki-gateway
    links:
      - prometheus:prometheus
      - loki-gateway:loki-gateway
      - alertmanager:alertmanager
      - influxdb:influxdb
    expose:
    - 3000
    ports:
      - 3000:3000
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/etc/grafana/grafana.ini:/etc/grafana/grafana.ini
      - ./grafana/provisioning/:/etc/grafana/provisioning/
    env_file:
      - ./env
    restart: always
    # entrypoint:
    #   - sh
    #   - -euc
    #   - |
    #     mkdir -p /etc/grafana/provisioning/datasources
    #     cat <<EOF > /etc/grafana/provisioning/datasources/ds.yaml
    #     apiVersion: 1
    #     datasources:
    #     - name: Loki
    #       type: loki
    #       access: proxy
    #       orgId: 1
    #       url: http://loki:3100
    #       basicAuth: false
    #       isDefault: true
    #       version: 1
    #       editable: false
    #     EOF
    #     /run.sh
    environment:
    #- TZ=UTC
    - GF_INSTALL_PLUGINS=grafana-clock-panel,natel-discrete-panel,grafana-piechart-panel
    - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
    - GF_AUTH_ANONYMOUS_ENABLED=true
    - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    - GF_DATAPROXY_TIMEOUT=310
    - GF_LOG_LEVEL={{ grafana_log_level }}
    - GF_DATAPROXY_LOGGING=true
    - GF_EXPLORE_ENABLED=true
    - GF_PATHS_CONFIG=/etc/grafana/grafana.ini
    networks:
    - loki

  # https://github.com/lux4rd0/grafana-loki-syslog-aio/blob/main/docker-compose-with-generator.yml
  syslog-ng:
    image: balabit/syslog-ng:latest
    container_name: syslog-ng
    command: -edv --control /syslog-ng/syslog-ng.ctl
{% if promtail_feature_flag %}
    depends_on:
    - promtail
{% endif %}
    networks:
      loki: null
    ports:
    - protocol: udp
      published: 514
      target: 514
    - protocol: tcp
      published: 601
      target: 601
    restart: always
    volumes:
    - ./syslog-ng/syslog-ng.conf:/etc/syslog-ng/syslog-ng.conf:ro
    - ./syslog-ng:/syslog-ng:rw

{% if syslog_ng_exporter_feature_flag %}
  syslog_ng_exporter:
    # build:
    #   context: ./syslog_ng_exporter
    image: brandond/syslog_ng_exporter:latest
    container_name: syslog_ng_exporter
    command:
    - '--telemetry.address=:9577'
    - '--telemetry.endpoint=/metrics'
    - '--socket.path=/syslog-ng/syslog-ng.ctl'
    # - '--log.level=info'
    depends_on:
    - syslog-ng
    networks:
      loki: null
    ports:
    - protocol: tcp
      published: 9577
      target: 9577
    restart: always
    volumes:
    - ./syslog-ng:/syslog-ng:rw
{% endif %}

{% if log_generator_feature_flag %}
  syslog-generator:
    build:
      context: ./syslog-generator
    container_name: syslog-generator
    depends_on:
    - syslog-ng
    networks:
      loki: null
{% endif %}

  pve-exporter:
    image: prompve/prometheus-pve-exporter
    container_name: pve-exporter
    labels:
    - "traefik.enable=true"
    - "traefik.http.routers.pve-exporter.rule=Host(`pve-exporter.{{ fqdn }}`)"
    - "traefik.http.routers.pve-exporter.entrypoints=web"
    - "traefik.http.routers.pve-exporter.service=pve-exporter"
    - "traefik.http.services.pve-exporter.loadbalancer.server.port=9221"
    - "traefik.port=9221"
    tty: true
    stdin_open: true
    ports:
    - "9221:9221/tcp"
    expose:
    - 9221
    volumes:
      - ./pve_exporter/pve_exporter/pve.yaml:/etc/prometheus/pve.yml
    restart: always
    deploy:
      mode: global
    env_file:
      - ./env
    command:
    - '--collector.status'
    - '--collector.version'
    - '--collector.node'
    - '--collector.cluster'
    - '--collector.resources'
    #environment:
    #- TZ=UTC
    networks:
    - loki
{% raw %}
    logging:
      driver: json-file
      options:
        tag: "{{.ImageName}}|{{.Name}}|{{.ImageFullID}}|{{.FullID}}"
{% endraw %}
